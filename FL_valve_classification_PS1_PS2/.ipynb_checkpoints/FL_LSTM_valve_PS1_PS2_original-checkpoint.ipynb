{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97580a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data shapes: X_ps1=(2205, 6000), X_ps2=(2205, 6000), y=(2205,)\n",
      "Combined data shape: (2205, 12000)\n",
      "Data normalization complete.\n",
      "Reshaped data for LSTM: (2205, 1, 12000)\n",
      "Splitting data into train and test sets...\n",
      "Training data shape: (1984, 1, 12000), Testing data shape: (221, 1, 12000)\n",
      "Simulating 3 federated clients...\n",
      "Creating LSTM model...\n",
      "Model created successfully.\n",
      "Client 1 - Train data shape: (594, 1, 12000), Test data shape: (67, 1, 12000)\n",
      "Creating LSTM model...\n",
      "Model created successfully.\n",
      "Client 2 - Train data shape: (594, 1, 12000), Test data shape: (67, 1, 12000)\n",
      "Creating LSTM model...\n",
      "Model created successfully.\n",
      "Client 3 - Train data shape: (594, 1, 12000), Test data shape: (67, 1, 12000)\n",
      "Training and aggregating client models...\n",
      "Training client 1...\n",
      "Training client model...\n"
     ]
    }
   ],
   "source": [
    "# import flwr as fl\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Load your data\n",
    "# X_ps1 = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Mahak_btp\\VSCode_FL_Mahak\\FL_Valve_Classification\\PS1.csv\", header = None).values\n",
    "# X_ps2 = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Mahak_btp\\VSCode_FL_Mahak\\FL_Valve_Classification\\PS2.csv\", header = None).values\n",
    "# y = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Mahak_btp\\VSCode_FL_Mahak\\FL_Valve_Classification\\valve_target_encoded.csv\",header = None).values.flatten()  # Ensure y is 1D\n",
    "\n",
    "# print(X_ps1.shape, X_ps2.shape, y.shape)\n",
    "# # (2205, 6000) (2205, 6000) (2205,)\n",
    "\n",
    "# # Combine the data\n",
    "# # Combine PS1 and PS2 into one array\n",
    "# X_combined = np.concatenate([X_ps1, X_ps2], axis=1)  # Shape: (2205, 12000)\n",
    "# print(X_combined.shape) \n",
    "\n",
    "# # Normalize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X_combined)\n",
    "\n",
    "# # Reshape the data for LSTM: (samples, time steps, features)\n",
    "# X_reshaped = X_scaled.reshape(2205, 1, 12000)  # Shape: (2205, 1, 12000)\n",
    "# print(X_reshaped.shape)  # Should print (2205, 1, 12000)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess the data\n",
    "def load_data():\n",
    "    print(\"Loading data...\")\n",
    "    X_ps1 = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Mahak_btp\\VSCode_FL_Mahak\\FL_Valve_Classification\\PS1.csv\", header=None).values\n",
    "    X_ps2 = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Mahak_btp\\VSCode_FL_Mahak\\FL_Valve_Classification\\PS2.csv\", header=None).values\n",
    "    y = pd.read_csv(r\"C:\\Users\\HP\\Downloads\\Mahak_btp\\VSCode_FL_Mahak\\FL_Valve_Classification\\valve_target_encoded.csv\", header=None).values.flatten()\n",
    "    print(f\"Data shapes: X_ps1={X_ps1.shape}, X_ps2={X_ps2.shape}, y={y.shape}\")\n",
    "\n",
    "    # Combine features from PS1 and PS2\n",
    "    X_combined = np.concatenate([X_ps1, X_ps2], axis=1)\n",
    "    print(f\"Combined data shape: {X_combined.shape}\")\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_combined)\n",
    "    print(\"Data normalization complete.\")\n",
    "\n",
    "    # Reshape to (samples, timesteps, features) for LSTM input\n",
    "    X_reshaped = X_scaled.reshape(2205, 1, 12000)\n",
    "    print(f\"Reshaped data for LSTM: {X_reshaped.shape}\")\n",
    "\n",
    "    return X_reshaped, y\n",
    "\n",
    "\n",
    "# Define the LSTM model structure\n",
    "def create_model(input_shape):\n",
    "    print(\"Creating LSTM model...\")\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(4, activation=\"softmax\")  # For 4 classes\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    print(\"Model created successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Simulate a federated learning client\n",
    "class FederatedClient:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.model = create_model(input_shape=(1, 12000))\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        print(\"Training client model...\")\n",
    "        self.model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=0)\n",
    "        print(\"Client model training complete.\")\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def evaluate(self, X_eval, y_eval, set_name=\"Test\"):\n",
    "        print(f\"Evaluating client model on {set_name} data...\")\n",
    "        loss, accuracy = self.model.evaluate(X_eval, y_eval, verbose=0)\n",
    "        print(f\"Client model {set_name} data - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        return loss, accuracy\n",
    "\n",
    "\n",
    "# Main federated learning simulation\n",
    "def federated_learning_simulation(num_clients):\n",
    "    # Load data\n",
    "    X_total, y_total = load_data()\n",
    "\n",
    "    # Split the data for train and test\n",
    "    print(\"Splitting data into train and test sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.10, random_state=104, stratify=y_total)\n",
    "    print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")\n",
    "\n",
    "    # Split data across clients\n",
    "    print(f\"Simulating {num_clients} federated clients...\")\n",
    "    data_per_client = len(X_train) // num_clients\n",
    "    clients = []\n",
    "    for i in range(num_clients):\n",
    "        X_client = X_train[i * data_per_client:(i + 1) * data_per_client]\n",
    "        y_client = y_train[i * data_per_client:(i + 1) * data_per_client]\n",
    "\n",
    "        # Split each client data into training and testing sets\n",
    "        X_client_train, X_client_test, y_client_train, y_client_test = train_test_split(X_client, y_client, test_size=0.1, random_state=42, stratify=y_client)\n",
    "        client = FederatedClient(X_client, y_client)\n",
    "        clients.append((client, X_client_train, y_client_train, X_client_test, y_client_test))\n",
    "        print(f\"Client {i + 1} - Train data shape: {X_client_train.shape}, Test data shape: {X_client_test.shape}\")\n",
    "\n",
    "    # Train each client model and aggregate weights\n",
    "    global_weights = None\n",
    "    print(\"Training and aggregating client models...\")\n",
    "    for i, (client, X_client_train, y_client_train, X_client_test, y_client_test) in enumerate(clients):\n",
    "        print(f\"Training client {i + 1}...\")\n",
    "        client_weights = client.train(X_client_train, y_client_train)\n",
    "        \n",
    "        # Evaluate client on its own training and testing data\n",
    "        train_loss, train_accuracy = client.evaluate(X_client_train, y_client_train, set_name=\"Training\")\n",
    "        test_loss, test_accuracy = client.evaluate(X_client_test, y_client_test, set_name=\"Testing\")\n",
    "\n",
    "        if global_weights is None:\n",
    "            global_weights = client_weights\n",
    "        else:\n",
    "            # Average weights for federated aggregation\n",
    "            global_weights = [(g + c) / 2 for g, c in zip(global_weights, client_weights)]\n",
    "    print(\"Client model training and aggregation complete.\")\n",
    "\n",
    "    # Set global model with aggregated weights and evaluate\n",
    "    global_model = create_model(input_shape=(1, 12000))\n",
    "    global_model.set_weights(global_weights)\n",
    "\n",
    "    # Evaluate global model on the original test data\n",
    "    print(\"Evaluating global model on overall test data...\")\n",
    "    test_loss, test_accuracy = global_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Global model on overall test data - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Number of simulated clients\n",
    "    NUM_CLIENTS = 3\n",
    "    federated_learning_simulation(NUM_CLIENTS)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e52b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
